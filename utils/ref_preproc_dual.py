# utils/ref_preproc_dual.py
# -*- coding: utf-8 -*-
import os
from dataclasses import dataclass
from typing import Optional, Tuple, List

import numpy as np
import soundfile as sf
import librosa
from scipy.signal import butter, sosfilt, iirnotch, lfilter

# å¯é€‰ï¼šæ›´å¼ºè°±å‡
try:
    import noisereduce as nr
    _HAS_NR = True
except Exception:
    _HAS_NR = False

# WebRTC VAD
try:
    import webrtcvad
    _HAS_VAD = True
except Exception:
    _HAS_VAD = False


@dataclass
class DualRefCfg:
    # é‡‡æ ·ä¸è¾“å…¥é™åˆ¶
    target_sr: int = 16000
    max_in_seconds: float = 60.0  # åŸå§‹å‚è€ƒæœ€é•¿è¯»å–æ—¶é•¿

    # å‚è€ƒç›®æ ‡æ—¶é•¿ï¼ˆğŸ‘‰ åŒè·¯ç‹¬ç«‹ï¼‰
    pick_seconds_embed: float = 6.0   # å£°çº¹/ç›¸ä¼¼åº¦ç”¨çš„å‚è€ƒæ—¶é•¿ï¼ˆè½»å¤„ç†ï¼‰
    pick_seconds_asr: float = 6.0     # ASR/æ–­å¥ç”¨çš„å‚è€ƒæ—¶é•¿ï¼ˆé‡å¤„ç†ï¼‰

    # ç«¯ç‚¹æ·¡å…¥æ·¡å‡º
    fade_ms: int = 12

    # æ»¤æ³¢
    highpass_hz: Optional[int] = 60
    lowpass_hz: Optional[int] = 8000
    hum_notch_hz: Optional[int] = None  # 50 æˆ– 60ï¼ˆNone=è‡ªåŠ¨åˆ¤æ–­ï¼‰

    # å½’ä¸€åŒ–
    peak_dbfs: float = -3.0
    rms_dbfs_embed: Optional[float] = -23.0
    rms_dbfs_asr: Optional[float] = -23.0

    # VAD
    use_vad: bool = True
    vad_aggr: int = 2
    vad_frame_ms: int = 20
    vad_pad_ms: int = 200

    # åŠ¨æ€å»å™ªé˜ˆå€¼ï¼ˆåŸºäº SNR/HNRï¼‰
    snr_mild_th: float = 15.0
    snr_bad_th: float = 8.0
    denoise_strength_embed_mild: float = 0.4
    denoise_strength_embed_light: float = 0.2
    denoise_strength_asr: float = 0.9

    # é€‰æ®µç­–ç•¥
    prefer_harmonic: bool = True
    crossfade_ms: float = 12.0


# def _ensure_mono(y: np.ndarray) -> np.ndarray:
#     return y.mean(axis=0) if y.ndim == 2 else y

def _ensure_mono_float32(y: np.ndarray) -> np.ndarray:
    if y.ndim == 2:
        y = y.mean(axis=0)
    if y.dtype != np.float32:
        y = y.astype(np.float32, copy=False)
    # é¿å… NaN/Inf
    y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0).astype(np.float32, copy=False)
    return y

def _to_float32(y: np.ndarray) -> np.ndarray:
    """æŠŠå„ç§æ•´å‹/æµ®ç‚¹ç»Ÿä¸€æˆ [-1,1] çš„ float32ã€‚"""
    if np.issubdtype(y.dtype, np.floating):
        y = y.astype(np.float32)
    else:
        # æœ‰ç¬¦å·æ•´å‹ â†’ å½’ä¸€åŒ–åˆ° [-1,1]
        info = np.iinfo(y.dtype)
        y = y.astype(np.float32) / max(abs(info.min), info.max)
    # æç«¯ä¿æŠ¤ï¼šé˜²æ­¢è¶…ç•Œ
    m = np.max(np.abs(y)) + 1e-12
    if m > 1.0:
        y = y / m
    return y


def _load_audio(path: str, target_sr: int) -> Tuple[np.ndarray, int]:
    y, sr = sf.read(path, always_2d=False)
    y = _ensure_mono_float32(y)
    if sr != target_sr:
        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr, fix=True)
        sr = target_sr
    return y, sr


def _peak_norm(y: np.ndarray, peak_dbfs: float) -> np.ndarray:
    y = y.astype(np.float32, copy=False)
    peak = float(np.max(np.abs(y))) + 1e-12
    target = 10 ** (peak_dbfs / 20.0)
    if peak > target:
        y = y * (target / peak)
    return y


def _rms_norm(y: np.ndarray, target_dbfs: float) -> np.ndarray:
    rms = float(np.sqrt(np.mean(y ** 2))) + 1e-12
    target = 10 ** (target_dbfs / 20.0)
    return (y * (target / rms)).astype(np.float32)


def _butter_sos(kind: str, cutoff_hz: float, sr: int, order: int = 4):
    nyq = sr * 0.5
    norm = cutoff_hz / nyq
    return butter(order, norm, btype=("highpass" if kind == "high" else "lowpass"), output="sos")


def _apply_filters(y: np.ndarray, sr: int, hp: Optional[int], lp: Optional[int]) -> np.ndarray:
    y = y.astype(np.float32)
    if hp:
        y = sosfilt(_butter_sos("high", hp, sr), y)
    if lp and lp < int(sr * 0.49):
        y = sosfilt(_butter_sos("low", lp, sr), y)
    return y.astype(np.float32)


def _apply_notch(y: np.ndarray, sr: int, freq: int) -> np.ndarray:
    # é™·æ³¢ 50/60Hzï¼ˆQ=30ï¼‰
    b, a = iirnotch(w0=freq/(sr/2), Q=30)
    return lfilter(b, a, y).astype(np.float32)


def _simple_denoise(y: np.ndarray, sr: int, strength: float) -> np.ndarray:
    if _HAS_NR:
        try:
            return nr.reduce_noise(y=y.astype(np.float32), sr=sr, stationary=False)
        except Exception:
            pass
    # è½»é‡è°±å‡ï¼ˆstrength è°ƒåˆ¶ï¼‰
    y = y.astype(np.float32)
    stft = librosa.stft(y, n_fft=1024, hop_length=256)
    S = np.abs(stft) + 1e-8
    noise = np.quantile(S, 0.10, axis=1, keepdims=True)
    Sd = np.maximum(S - strength * noise, 0.0)
    yd = librosa.istft(Sd * np.exp(1j * np.angle(stft)), hop_length=256, length=len(y))
    return yd.astype(np.float32)


def _bytes_frames(y16: bytes, sr: int, frame_ms: int) -> List[bytes]:
    n = int(sr * frame_ms / 1000) * 2
    return [y16[i:i+n] for i in range(0, len(y16), n)]


def _vad_segments(y: np.ndarray, sr: int, aggr: int, frame_ms: int, pad_ms: int) -> List[Tuple[int,int]]:
    assert _HAS_VAD, "webrtcvad æœªå®‰è£…"
    s16 = (y * 32767).clip(-32768, 32767).astype(np.int16).tobytes()
    frames = _bytes_frames(s16, sr, frame_ms)
    hop = int(sr * frame_ms / 1000)
    pad = int(sr * pad_ms / 1000)

    segs = []
    cur = None
    vad = webrtcvad.Vad(aggr)
    for i, f in enumerate(frames):
        if len(f) != len(frames[0]):
            break
        try:
            sp = vad.is_speech(f, sr)
        except Exception:
            sp = False
        if sp and cur is None:
            cur = [i*hop, i*hop+hop]
        elif sp and cur is not None:
            cur[1] = i*hop+hop
        elif (not sp) and cur is not None:
            segs.append(tuple(cur)); cur = None
    if cur is not None:
        segs.append(tuple(cur))

    # åˆå¹¶ + pad
    merged = []
    for s,e in segs:
        s = max(0, s-pad); e = min(len(y), e+pad)
        if not merged or s > merged[-1][1] + pad:
            merged.append([s,e])
        else:
            merged[-1][1] = e
    return [(s,e) for s,e in merged]


def _fade_io(y: np.ndarray, sr: int, ms: int) -> np.ndarray:
    n = min(int(sr*ms/1000), len(y)//2)
    if n <= 0:
        return y
    fade_in = np.linspace(0,1,n, dtype=np.float32)
    fade_out= np.linspace(1,0,n, dtype=np.float32)
    y = y.copy()
    y[:n] *= fade_in
    y[-n:] *= fade_out
    return y.astype(np.float32)


def _energy(x: np.ndarray) -> float:
    return float(np.mean(x.astype(np.float32) ** 2))


def _hnr_score(x: np.ndarray, sr: int) -> float:
    """
    ç²—ç•¥ HNRï¼šHarmonic/Percussive after HPSS on STFT magnitude
    ä¿è¯è¾“å…¥ä¸º float32ï¼›æ®µå¤ªçŸ­æ—¶å›é€€ã€‚
    """
    x = x.astype(np.float32, copy=False)
    if len(x) < 1024:  # æçŸ­æ—¶ç›´æ¥å›é€€
        return 1.0
    try:
        X = librosa.stft(x, n_fft=1024, hop_length=256)
        H, P = librosa.effects.hpss(np.abs(X))
        h = np.mean(np.abs(H))
        p = np.mean(np.abs(P)) + 1e-8
        return float(h / p)
    except Exception:
        return 1.0


def _pick_segments(y: np.ndarray, sr: int, segs: List[Tuple[int,int]],
                   want_sec: float, prefer_harmonic: bool, crossfade_ms: float) -> np.ndarray:
    """æŒ‰è¯„åˆ†æŒ‘é€‰è‹¥å¹²æ®µæ‹¼æ¥åˆ°ç›®æ ‡æ—¶é•¿ï¼ˆä¸å¤Ÿå°±ç”¨ç°æœ‰é•¿åº¦ï¼Œä¸æŠ¥é”™ï¼‰"""
    y = y.astype(np.float32)
    if want_sec <= 0:
        return np.zeros(0, dtype=np.float32)

    if not segs:
        take = min(len(y), int(want_sec*sr))
        return y[:take]

    scored = []
    for s,e in segs:
        seg = y[s:e].astype(np.float32)
        if len(seg) < int(0.1*sr):  # æ¥µçŸ­ç‰‡æ®µè·³é
            continue
        if prefer_harmonic:
            score = 0.7 * _hnr_score(seg, sr) + 0.3 * _energy(seg)
        else:
            score = _energy(seg)
        scored.append((score, s, e))
    if not scored:
        take = min(len(y), int(want_sec*sr))
        return y[:take]

    scored.sort(key=lambda t: t[0], reverse=True)

    need = int(want_sec * sr)
    got = 0
    out = []
    xf = int(sr * crossfade_ms / 1000)
    for _, s, e in scored:
        if got >= need:
            break
        seg = y[s:e]
        take = min(len(seg), need - got)
        seg = seg[:take]
        if not out:
            out.append(seg)
        else:
            a = out[-1]
            if xf > 0 and len(a) > xf and len(seg) > xf:
                fo = np.linspace(1,0,xf, dtype=np.float32)
                fi = np.linspace(0,1,xf, dtype=np.float32)
                a[-xf:] = a[-xf:] * fo + seg[:xf] * fi
                out[-1] = a
                out.append(seg[xf:])
            else:
                out.append(seg)
        got += take

    return np.concatenate(out).astype(np.float32) if out else y[:need]


def _snr_estimate(y: np.ndarray, sr: int, segs: List[Tuple[int,int]]) -> float:
    """åŸºäº VADï¼šspeech æ®µèƒ½é‡ / éè¯­éŸ³æ®µèƒ½é‡ï¼ˆdBï¼‰"""
    y = y.astype(np.float32)
    mask = np.zeros(len(y), dtype=bool)
    for s,e in segs:
        mask[s:e] = True
    speech = y[mask]
    noise = y[~mask]
    if len(speech) < sr*0.2 or len(noise) < sr*0.2:
        # fallbackï¼šåˆ†ä½æ•°ä¼°è®¡
        S = np.abs(librosa.stft(y, n_fft=1024, hop_length=256))
        sp = np.quantile(S, 0.80); ns = np.quantile(S, 0.20) + 1e-8
        return float(20*np.log10(sp/ns))
    ps = np.mean(speech**2) + 1e-12
    pn = np.mean(noise**2) + 1e-12
    return float(10*np.log10(ps/pn))


def _auto_detect_hum(y: np.ndarray, sr: int) -> Optional[int]:
    """ç®€æ˜“ 50/60Hz å—¡å£°æ£€æµ‹ï¼šå“ªä¸ªå³°æ›´é«˜è¿”å›å“ªä¸ªï¼ˆå¼±åˆ™ä¸åšï¼‰ã€‚"""
    y = y.astype(np.float32)
    S = np.abs(librosa.stft(y, n_fft=4096, hop_length=1024)).mean(axis=1)
    freqs = librosa.fft_frequencies(sr=sr, n_fft=4096)

    def band_power(f0, bw=3):
        idx = np.where((freqs >= f0-bw) & (freqs <= f0+bw))[0]
        return float(S[idx].mean()) if len(idx) > 0 else 0.0

    p50, p60 = band_power(50), band_power(60)
    if max(p50, p60) < 0.001:
        return None
    return 50 if p50 >= p60 else 60


def preprocess_reference_dual(
    in_path: str,
    out_dir: str,
    cfg: DualRefCfg = DualRefCfg()
) -> Tuple[str, str]:
    """
    è¯»å–å‚è€ƒéŸ³é¢‘ â†’ è½»/é‡ä¸¤æ¡å‚è€ƒï¼š
      - embed_ref.wavï¼ˆè½»å¤„ç†ï¼Œä¾›éŸ³è‰²/ç›¸ä¼¼åº¦æŠ½å–ï¼›ç›®æ ‡é•¿åº¦ cfg.pick_seconds_embedï¼‰
      - asr_ref.wav   ï¼ˆé‡å¤„ç†ï¼Œä¾›ASR/å¯¹é½/å¯æ‡‚æ€§ï¼›ç›®æ ‡é•¿åº¦ cfg.pick_seconds_asrï¼‰
    è¿”å› (embed_ref_path, asr_ref_path)
    """
    os.makedirs(out_dir, exist_ok=True)
    y, sr = _load_audio(in_path, cfg.target_sr)

    # é™æ—¶
    if cfg.max_in_seconds and len(y) > cfg.max_in_seconds*sr:
        y = y[:int(cfg.max_in_seconds*sr)]

    # åˆæ­¥æ»¤æ³¢ï¼ˆè½»ï¼‰
    y0 = _apply_filters(y, sr, cfg.highpass_hz, cfg.lowpass_hz)

    # VAD
    if cfg.use_vad and _HAS_VAD:
        segs = _vad_segments(y0, sr, cfg.vad_aggr, cfg.vad_frame_ms, cfg.vad_pad_ms)
    else:
        segs = [(0, len(y0))]

    # SNR è¯„ä¼°ï¼ˆç”¨äºå»å™ªå†³ç­–ï¼‰
    snr = _snr_estimate(y0, sr, segs)

    # è‡ªåŠ¨ 50/60Hz å—¡å£°é™·æ³¢ï¼ˆå¦‚æœæ˜æ˜¾ï¼‰
    hum = cfg.hum_notch_hz or _auto_detect_hum(y0, sr)
    if hum in (50, 60):
        y0 = _apply_notch(y0, sr, hum)

    # â€”â€” å£°çº¹å‚è€ƒï¼ˆè½»å¤„ç†ï¼‰â€”â€”
    y_embed = _pick_segments(y0, sr, segs, cfg.pick_seconds_embed, cfg.prefer_harmonic, cfg.crossfade_ms)
    if snr < cfg.snr_mild_th:
        strength = cfg.denoise_strength_embed_light if snr < cfg.snr_bad_th else cfg.denoise_strength_embed_mild
        y_embed = _simple_denoise(y_embed, sr, strength=strength)
    y_embed = _fade_io(y_embed, sr, cfg.fade_ms)
    y_embed = _peak_norm(y_embed, cfg.peak_dbfs)
    if cfg.rms_dbfs_embed is not None:
        y_embed = _rms_norm(y_embed, cfg.rms_dbfs_embed)
    embed_path = os.path.join(out_dir, "embed_ref.wav")
    sf.write(embed_path, y_embed, sr)

    # â€”â€” ASR å‚è€ƒï¼ˆé‡å¤„ç†ï¼‰â€”â€”
    y_asr = _pick_segments(y0, sr, segs, cfg.pick_seconds_asr, cfg.prefer_harmonic, cfg.crossfade_ms)
    y_asr = _simple_denoise(y_asr, sr, strength=cfg.denoise_strength_asr)
    y_asr = _apply_filters(y_asr, sr, cfg.highpass_hz or 60, min(cfg.lowpass_hz or 8000, 7500))
    y_asr = _fade_io(y_asr, sr, cfg.fade_ms)
    y_asr = _peak_norm(y_asr, cfg.peak_dbfs)
    if cfg.rms_dbfs_asr is not None:
        y_asr = _rms_norm(y_asr, cfg.rms_dbfs_asr)
    asr_path = os.path.join(out_dir, "asr_ref.wav")
    sf.write(asr_path, y_asr, sr)

    return embed_path, asr_path
